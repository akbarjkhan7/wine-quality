#Load libraries
library(tidyr)
library(caret)
library(glmnet)
library(randomForest)
library(GGally)
library(ggplot2)
library(dplyr)

#Load and combine dataset
red = read.csv("winequality-red.csv", sep = ";")
white = read.csv("winequality-white.csv", sep = ";")
#want to see if loaded correct
nrow(red)
nrow(white)
head(red)

#label before merging the two
red$type = "red"
white$type = "white"
#now merging the two
wine = rbind(red, white)

#Cleaning Data
#first checking structure and summary stats
str(wine)
summary(wine)
#check for any missing values
wine %>% filter(!complete.cases(.))

#Converting variables into correct types
wine = wine %>%
  mutate(
    type = as.factor(type),
    quality_bin = as.factor(ifelse(quality >= 6, 1, 0))
  )

#class balance for each wine type
table(wine$quality_bin, wine$type)

#Train and test split
set.seed(123)
trainIndex = createDataPartition(wine$quality_bin, p = 0.75, list = FALSE)
train = wine[trainIndex, ]
test = wine[-trainIndex, ]

#EDA
#scatterplot of wine quality (Red and white)
ggplot(wine, aes(x = type, y = quality, color = type)) +
  geom_point(position = position_jitter(width = 0.2), alpha = 0.5) +
  theme_bw() +
  labs(title = "Wine Quality Distribution by Type",
       x = "Wine Type",
       y = "Wine Quality")
#boxplots for the selected predictors
print(
  ggplot(wine, aes(x = type, y = alcohol)) +
    geom_boxplot(fill = "lightblue") +
    theme_bw()
)

print(
  ggplot(wine, aes(x = type, y = `residual.sugar`)) +
    geom_boxplot(fill = "lightgreen") +
    theme_bw()
)

print(
  ggplot(wine, aes(x = type, y = `volatile.acidity`)) +
    geom_boxplot(fill = "salmon") +
    theme_bw()
)
#pairwise plot of first 6 features
pair_data = wine[, c(1:6)]
pair_data$type = wine$type
ggpairs(pair_data) + theme_bw()

#Lasso Classification
lambdas = seq(0.01, 2, by = 0.01)
#10fold cross validation
ctrl_kfold = trainControl(method = "cv", number = 10)
#training lasso model 
lasso_kfold = train(
  quality_bin ~ . - quality - quality_bin,
  data = train,
  method = "glmnet",
  metric = "Accuracy",
  tuneGrid = expand.grid(alpha = 1, lambda = lambdas),
  trControl = ctrl_kfold,
  thresh = 1e-10
)
#now print best lamba and model cofficents
print(lasso_kfold$finalModel$lambdaOpt)
coef(lasso_kfold$finalModel, lasso_kfold$bestTune$lambda)

#Cross validation plot 
cv_lassoplot = ggplot(lasso_kfold$results) +
  geom_point(aes(x = lambda, y = Accuracy), color = "red") +
  geom_errorbar(aes(x = lambda, ymin = Accuracy - AccuracySD, ymax = Accuracy + AccuracySD),
                width = 0.3, color = "lightgray") +
  labs(title = "Cross-Validation Results (Lasso)", x = "Lambda", y = "Accuracy") +
  theme_bw()
#highlight best lambda
lasso_lambda = lasso_kfold$bestTune$lambda
best_acc = lasso_kfold$results %>% filter(lambda == lasso_lambda)
cv_lassoplot +
  geom_point(data = best_acc, aes(x = lambda, y = Accuracy), colour = "purple4", size = 3) +
  geom_label(data = best_acc, label = "Winner", aes(x = lambda, y = Accuracy),
             nudge_x = 0.1, nudge_y = 0.01)

#confusing matrix for lasso
#test data to predict
x_test = model.matrix(quality_bin ~ . - quality - quality_bin, data = test)[, -1]
pred_prob_lasso = predict(lasso_kfold$finalModel,
                          newx = x_test,
                          s = lasso_lambda,
                          type = "response")

pred_class_lasso = ifelse(pred_prob_lasso > 0.5, 1, 0)

#conf matrix for lasso
conf_lasso = confusionMatrix(factor(pred_class_lasso), factor(test$quality_bin))
print(conf_lasso)

#Random Forest Classification
set.seed(42)
rf_model = randomForest(quality_bin ~ . -quality, data = train, importance = TRUE)
pred_rf = predict(rf_model, newdata = test)
conf_rf = confusionMatrix(pred_rf, test$quality_bin)
print(conf_rf)

#Variable importance plot
varImpPlot(rf_model, sort = TRUE, pch = 16)

#MDS for Random forest proximity
set.seed(404)
rf_mds = randomForest(quality_bin ~ . - quality, data = train, importance = TRUE, proximity = TRUE)
MDSplot(rf_mds, train$quality_bin)

#PDP histograms for alcohol, volatile and sulphates
ggplot(wine, aes(x = alcohol, fill = quality_bin)) +
  geom_histogram(alpha = 0.7, bins = 30) +
  scale_fill_manual(values = c("firebrick", "darkgreen")) +
  labs(title = "Alcohol Distribution by Wine Quality", x = "Alcohol", y = "Count") +
  theme_bw()

ggplot(wine, aes(x = volatile.acidity, fill = quality_bin)) +
  geom_histogram(alpha = 0.7, bins = 30) +
  scale_fill_manual(values = c("firebrick", "darkgreen")) +
  labs(title = "Volatile Acidity by Wine Quality", x = "Volatile Acidity", y = "Count") +
  theme_bw()

ggplot(wine, aes(x = sulphates, fill = quality_bin)) +
  geom_histogram(alpha = 0.7, bins = 30) +
  scale_fill_manual(values = c("firebrick", "darkgreen")) +
  labs(title = "Sulphates by Wine Quality", x = "Sulphates", y = "Count") +
  theme_bw()

#RMSE Distribution for Random Forest using bootstrap
n_sample = 500
b_sample_size = floor(0.8 * nrow(train))
RMSE_rf = rep(NA, n_sample)

for (b in 1:n_sample) {
  ind = sample(1:nrow(train), size = b_sample_size, replace = TRUE)
  train_boot = train[ind, ]
  test_oob = train[-unique(ind), ]
  rf_b = randomForest(quality_bin ~ . - quality, data = train_boot)
  pred_b = predict(rf_b, newdata = test_oob, type = "response")
  rmse = sqrt(mean((as.numeric(pred_b) - as.numeric(test_oob$quality_bin))^2))
  RMSE_rf[b] = rmse
}
#histogram of RMSE scores
hist(RMSE_rf, breaks = 30, main = "RMSE Distribution - Random Forest (Bootstrap)",
     xlab = "RMSE", col = "skyblue")

#Summary stats of RMSE
summary(RMSE_rf)
mean(RMSE_rf)

#Summary of model comparison
print("Lasso Classification Accuracy:")
print(best_acc$Accuracy)

print("Random Forest Accuracy:")
print(conf_rf$overall["Accuracy"])

#For model comparison for Lasso Regression
lasso_accuracy = conf_lasso$overall["Accuracy"]
lasso_kappa = conf_lasso$overall["Kappa"]
lasso_sens = conf_lasso$byClass["Sensitivity"]
lasso_spec = conf_lasso$byClass["Specificity"]
lasso_precision = conf_lasso$byClass["Pos Pred Value"]
lasso_bal_acc = conf_lasso$byClass["Balanced Accuracy"]

#For model comparison for random forest
rf_accuracy = conf_rf$overall["Accuracy"]
rf_kappa = conf_rf$overall["Kappa"]
rf_sens = conf_rf$byClass["Sensitivity"]
rf_spec = conf_rf$byClass["Specificity"]
rf_precision = conf_rf$byClass["Pos Pred Value"]
rf_bal_acc = conf_rf$byClass["Balanced Accuracy"]
